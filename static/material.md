姓名：张家瑄
image: /static/images/self.jpg
邮件：12313226@mail.sustech.edu.cn
github主页：https://github.com/zhangjiaxuan-Xuan

研究方向：
- 类人机器人智能：寻找新的人工智能范式，脱离现有端到端模型的限制，实现类人思维与能力。
- 人机交互：以人为本，让与人互动的机器人系统作为单独的个体辅助人类，而非人类的模仿者。

升学计划:
- 申请2027年秋季入学的美国全奖博士项目，目标院校包括斯坦福大学、加州大学伯克利分校、麻省理工学院等。

教育经历：
- 南方科技大学 机器人工程 本科在读 (2023.09 - 至今)
- 西湖大学Milab 实习生 （2025.06 - 2025.09）

发表：
- VLA²: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation https://arxiv.org/abs/2510.14902 Han Zhao, **Jiaxuan Zhang**, Wenxuan Song, Pengxiang Ding, Donglin Wang

abstract：Current vision-language-action (VLA) models, pre-trained on large-scale robotic data, exhibit strong multi-task capabilities and generalize well to variations in visual and language instructions for manipulation. However, their success rate drops significantly when faced with object concepts outside the training data, such as unseen object descriptions and textures in the dataset. To address this, we propose a novel agentic framework, VLA^2, which leverages OpenVLA as the execution backbone and effectively leverages external modules such as web retrieval and object detection to provide visual and textual knowledge about target objects to the VLA. This approach mitigates generalization failure when handling out-of-distribution objects. Based on the LIBERO simulation environment, we introduced novel objects and object descriptions to construct a new evaluation benchmark with three difficulty levels to test the effectiveness of our method. Our framework successfully outperformed the current state-of-the-art models on our designed hard-level generalization benchmark. Compared to the standalone OpenVLA baseline, VLA^2 achieves a 44.2% improvement in the success rate in the hard-level benchmark and an average improvement of 20.2% in all customized environments without any performance degradation on in-domain tasks. Project website: this https URL：https://vla-2.github.io/

- IROS2025, Feature Matching-Based Gait Phase Prediction for Obstacle Crossing Control of Powered Transfemoral Prosthesis https://arxiv.org/abs/2510.24676 Jiaxuan Zhang, Yuqaun Leng, Yixuan Guo, Chenglong Fu

abstract：For amputees with powered transfemoral prosthetics, navigating obstacles or complex terrain remains challenging. This study addresses this issue by using an inertial sensor on the sound ankle to guide obstacle-crossing movements. A genetic algorithm computes the optimal neural network structure to predict the required angles of the thigh and knee joints. A gait progression prediction algorithm determines the actuation angle index for the prosthetic knee motor, ultimately defining the necessary thigh and knee angles and gait progression. Results show that when the standard deviation of Gaussian noise added to the thigh angle data is less than 1, the method can effectively eliminate noise interference, achieving 100\% accuracy in gait phase estimation under 150 Hz, with thigh angle prediction error being 8.71\% and knee angle prediction error being 6.78\%. These findings demonstrate the method's ability to accurately predict gait progression and joint angles, offering significant practical value for obstacle negotiation in powered transfemoral prosthetics.